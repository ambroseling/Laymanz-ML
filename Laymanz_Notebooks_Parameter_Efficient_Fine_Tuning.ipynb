{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMGa4otlDSEl"
      },
      "source": [
        "# Laymanz Notebooks: Parameter Efficient Fine-Tuning\n",
        "Author: Ambrose Ling\n",
        "\n",
        "**What is this notebook about?**\n",
        "\n",
        "In this notebook, we will go over some of the most fundamental ideas behind parameter efficient fine-tuning, how they work and why they have been a major advancement in the field of computer vision and generative artifical intelligence. We hope that you can walk away capable of leveraging these techniques to fine-tune your own language models or diffusion models.\n",
        "\n",
        "**What do I need to set up my environment?**\n",
        "\n",
        "All of our notebooks will only use numpy, pytorch, matplotlib for visualizations. We will not use any other third-party libraries for model development, optimization or anything like that.\n",
        "\n",
        "**How is this notebook structured?**\n",
        "1.\n",
        "2.\n",
        "3.\n",
        "\n",
        "\n",
        "**Covered papers in this notebook**\n",
        "* LoRA\n",
        "* GaLoRE\n",
        "* DoRA\n",
        "\n",
        "\n",
        "(will do after finishing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# What is Paramter Efficient Fine Tuning\n",
        "\n",
        "PEFT aims to leverage methods that reduce the cost of fine-tuning neural network models.\n",
        "Businesses, engineers, researchers may want to fine-tune state of the art language models or vision models to perform very specialized tasks for them. \n",
        "\n",
        "However the main bottleneck is that existing fine-tuning methods may involve full network training on these large models, which requires a lot of computational resources.\n",
        "\n",
        "If I want to fine-tune a model for multiple different tasks, it is very time consuming and expensive.\n",
        "\n",
        "## How to estimate the computational resources required for your model?\n",
        "- Lets assume that your model $\\theta$ has 1 billion parameters\n",
        "- The way we would calculate the memory requirement for fine-tuning such a model is as follows\n",
        "    - Parameters: 1B $\\times$ 4 bytes (32 bits)\n",
        "    - Gradients: 1B $\\times$ 4 bytes (32 bits)\n",
        "    - Optimizer States: 1B  $\\times$ 4 bytes (32 bits)$\\times$  2 (depending on the optimizer, Adam saves 2 moment statistics per parameter)\n",
        "    - Activations: can vary depending on the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear = nn.Linear(10,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.nn.modules.linear.Linear"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRUf7dezEJr2"
      },
      "source": [
        "## Low Rank Adaptation Fine Tuning (LoRA)\n",
        "\n",
        "**What is LoRA?**\n",
        "LoRA stands for Low Rank Adaptation fine-tuning. LoRA parametrizes the weight update matrix $\\Delta W$ as a low rank matrix. Authors found \n",
        "that update matrices are intrinsically low rank.\n",
        "\n",
        "**What is the goal of LoRA?**\n",
        "\n",
        "The main goal of LoRA is to enable fine-tuning of primiarly Large Language Models (also Diffusion Models) in a parameter efficient way,\n",
        "meaning without having to fine-tune or update all the weights of our model. This is desirable as this can reduce the computational cost when fine-tuning \n",
        "Large Language Models or Diffusion Models on downstream tasks\n",
        "\n",
        "**How does it work?**\n",
        "* Assume we have a pretrained model $\\theta$ where it has linear layers with weights $W_0$:\n",
        "* when we fine-tune our model, we freeze $W_0$, which prevents the pretrained weights from having gradient updates\n",
        "* LoRA decomposes the weight update matrix into 2 matrices $A \\in R^{r \\times k}$ and $B \\in R^{d \\times r}$\n",
        "* where we select $r$ , which is the rank and $r$ should be much smaller than $k$ or $d$\n",
        "* The paper showed that finetuning perforamnce using a small $r$ is on par with a large $r$ that would be used in full-finetuning \n",
        "* This shows that increasing $r$ does not help the weight update matrix cover more meaningful subspaces\n",
        "* The update formula during fine-tuning is as follows:\n",
        "    - $xW_{updated}$ = $xW_0$ + $x\\Delta W$\n",
        "    - $xW_{updated}$ = $xW_0$ + $x(A \\cdot B)\\cdot\\frac{\\alpha}{r}$\n",
        "    - where $r$ refers to the rank of low rank parametrization, $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets see analyze the dimensionality of the weight matrices\n",
        "d = 100 # rows \n",
        "k = 200 # columns\n",
        "\n",
        "r = 64 # the intrinsic low rank\n",
        "W_0 = torch.randn(d,k) \n",
        "\n",
        "A = torch.randn(r,k)\n",
        "B = torch.randn(d,r)\n",
        "\n",
        "x = torch.randn(k,k)\n",
        "\n",
        "W_0 = W_0 \n",
        "delta_W = (A @ B) @ x\n",
        "\n",
        "assert W_0.shape == delta_W.shape\n",
        "\n",
        "y = W_0 + delta_W \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why does it work?\n",
        "- It works because of this: there exists an intrinsic dimension\n",
        "    - Intrinsic dimension means the **minimum number of parameters required to achieve good performance**\n",
        "    - It also means the **lowest dimensional subspace** we can optimize our objective function in\n",
        "    - We fine-tune the model using this formula:\n",
        "    $$\n",
        "    \\theta^d = \\theta_0^D + P(\\theta^d)\n",
        "    $$\n",
        "    where:\n",
        "    * D is some higher dimension, or original dimensionality of the pretrained parameters\n",
        "    * d is some lower dimension, the dimensionality we want to perform optimization in for our \n",
        "    * P is the projection function or matrix that transforms the lower dimensional parameters to original dimensionality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Ckp6US9r8iDrEP9jW3m3VA.png\" ></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywo1YEmuEyrd"
      },
      "outputs": [],
      "source": [
        "class LoRA(nn.Module):\n",
        "    def __init__(self,rank,scale,layer):\n",
        "        self.rank = rank\n",
        "        self.scale = scale\n",
        "        self.a = nn.Parameter(torch.randn(10,self.rank))\n",
        "        self.b = nn.Parameter(torch.randn(self.rank,self.rank))\n",
        "        nn.init.normal(self.a.weight)\n",
        "        nn.init.normal(self.a.weight)\n",
        "        nn.init.zero(self.b.weight)\n",
        "        nn.init.zero(self.b.weight)\n",
        "    def forward(self,x):\n",
        "        x = x + self.a @ self.b *(self.scale/self.rank)\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVD decomposition & LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Applying LoRA to a pretrained language model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Low Rank Adaptation Fine Tuning (GaLoRE)\n",
        "\n",
        "**What is GaLoRE?**\n",
        "GaLoRE is a paper released recently aiming to tackle certain limitations of vanilla LoRA\n",
        "GaLoRE stands for gradient low-rank projection, which is a training method that allows you to still \n",
        "train with full parameters but is more **memory efficient** \n",
        "\n",
        "\n",
        "**Some of the main problems with LoRA**\n",
        "- LoRA is not able to reach good performance compared to full-parameter fine-tuning\n",
        "    - cause 1: the LoRA reparametrization changes the training dynamics\n",
        "    - cause 2: the optimal weight matrices are not low rank\n",
        "\n",
        "**How does it work?**\n",
        "- GaLoRE is used to fine-tune pretrained langauge models\n",
        "- GaLoRE approximates the gradient matrices as low rank rather than the paramter matrices (gradient matrices show to have slowly changing low-rank structure)\n",
        "- We compute 2 **projection matrices** $P \\in R^{m \\times r}$ and $Q \\in R^{n \\times r}$ to project gradient matrices to **low rank form**, $P^TGQ$\n",
        "- Only very infrequent updates applied to the projection matrices\n",
        "- GaLoRE aims to reduce the gradient statistics of both first-order and second-order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep dive into how it works\n",
        "\n",
        "In full rank training, we represent the weight update rule to be:\n",
        "$$\n",
        "W_T = W_0 + n \\Sigma_{t=0}^{T-1} \\tilde{G_t} = W_0 + n \\Sigma_{t=0}^{T-1} \\rho_t (\\tilde{G_t})\n",
        "$$\n",
        "\n",
        "* $W_T$ is weight matrix after $T$ training steps\n",
        "* $W_0$ is the inital weight matrix\n",
        "* $ \\tilde{G_t}$ is the final gradient matrix to be added to the weight matrix.\n",
        "* $\\rho_t$ is stateful gradient regularizer (optimizer)\n",
        "\n",
        "\n",
        "In low-rank training, we represent the weight update rule to be:\n",
        "$$\n",
        "W_T = W_0 + B_{T}A_{T}\n",
        "$$\n",
        "* $B \\in R^{m \\times r}$ is the low rank gradient matrix (low rank adaptors)\n",
        "* $A \\in R^{r \\times n}$ is the low rank projection matrix (low rank adaptors)\n",
        "\n",
        "In GaLore, we represent tje weight update rule to be:\n",
        "$$\n",
        "W_T = W_0 + n \\Sigma_{t=0}^{T-1} \\tilde{G_t}, \\tilde{G_t} = P_t\\rho_t(P_t^TG_tQ_t)Q_t^T\n",
        "$$\n",
        "* $P_t,Q_t \\in R^{m \\times r}, \\in R^{n \\times r}$ are projection matrices\n",
        "\n",
        "## Memory consumption comparison\n",
        "In full rank training:\n",
        "- Adam: $M,V \\in R^{m \\times n}$  \n",
        "- Gradient matrix: $G \\in R^{m \\times n}$\n",
        "- Weight matrix: $W \\in R^{m \\times n}$\n",
        "Total: $3mn$\n",
        "\n",
        "In LoRA training:\n",
        "- Adam: $M \\in R^{m \\times r},V \\in R^{n \\times r}$ for $A$,  $M \\in R^{m \\times r},V \\in R^{n \\times r}$ for $B$\n",
        "- Gradient matrix: $G \\in R^{m \\times n}$\n",
        "- Weight matrix: $W \\in R^{m \\times n}$, $A \\in R^{m \\times r}$,$B \\in R^{n \\times r}$\n",
        "Total: $$\n",
        "\n",
        "In GaLoRE training:\n",
        "- Adam: $M,V \\in R^{n \\times r}$  \n",
        "- Gradient matrix: $G \\in R^{n \\times r}$\n",
        "- Weight matrix: $W \\in R^{m \\times n}$\n",
        "- Projection matrices: $P \\in R^{m \\times r}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Original Adam Optimizer Algorithm**\n",
        "<center><a href=\"https://ibb.co/JK5nkmd\"><img src=\"https://i.ibb.co/xDJh5Xs/Screenshot-2024-06-05-at-1-32-18-PM.png\" alt=\"Screenshot-2024-06-05-at-1-32-18-PM\" border=\"0\"></a></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainng code for the Adam Optimizer\n",
        "\n",
        "from torch.optim import Optimizer\n",
        "import math\n",
        "\n",
        "class Adam(Optimizer):\n",
        "    def  __init__(self,params,lr = 1e-6,betas = (0.99,0.9),eps=1e-6,weight_decay=0.0):\n",
        "        defaults = dict(lr=lr,betas=betas,weight_decay=weight_decay,eps=eps)\n",
        "        super().__init__(params,defaults=defaults)\n",
        "    def step(self,closure=None):\n",
        "        #Iterature through all the parameter \n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "                step_size = group['lr']\n",
        "                # state is a dictionary that holds all the optimizer configurations for each parameter\n",
        "                if len(state) ==0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    state['exp_avg_sqr'] = torch.zeros_like(p.data)\n",
        "                exp_avg = state['exp_avg'] #first moment estimate\n",
        "                exp_avg_sqr = state['exp_avg_sqr'] # second moment estimate\n",
        "                beta1,beta2 = group['betas'] # get betas\n",
        "                exp_avg.mul_(beta1).add_((1-beta1),grad) #update biased first moment estimate\n",
        "                exp_avg_sqr.mul(beta2.addcmul_((1-beta2)),grad,grad) # update biased second moment estimate\n",
        "                denom = exp_avg_sqr.sqrt().add_(group['eps'])\n",
        "\n",
        "                # If there is bias correction\n",
        "                if group['bias_correction'] == True:\n",
        "                    bias_corrected_first_moment = 1 - beta1 ** state['step']\n",
        "                    bias_corrected_second_moment = 1 - beta2 ** state['step']\n",
        "                    step_size = step_size * math.sqrt(bias_corrected_second_moment) / bias_corrected_first_moment\n",
        "\n",
        "                # Weight update\n",
        "                p.data.addcdiv_(-step_size,exp_avg,denom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**GaLoRE+Adam Optimizer Algorithm**\n",
        "<center><a href=\"https://ibb.co/nDD9Sj7\"><img src=\"https://i.ibb.co/gDDNCJS/Screenshot-2024-06-05-at-4-02-38-PM.png\" alt=\"Screenshot-2024-06-05-at-4-02-38-PM\" border=\"0\"></a></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainng code for the GaLoRE Optimizer (Ambrose's implementation)\n",
        "\n",
        "from torch.optim import Optimizer\n",
        "import torch\n",
        "import math\n",
        "\n",
        "class GaLoREOptimizer(Optimizer):\n",
        "    def  __init__(self,params,lr = 1e-6,betas = (0.99,0.9),eps=1e-6,weight_decay=0.0,rank=32,subspace_freq=10,lora_scale=1.0):\n",
        "        defaults = dict(lr=lr,betas=betas,weight_decay=weight_decay,eps=eps, )\n",
        "        self.subspace_freq = subspace_freq # corresponds to T, subspace change frequency\n",
        "        self.lora_rank = rank # corresponds to LoRA rank\n",
        "        self.scaling_factor = lora_scale\n",
        "        super(GaLoREOptimizer,self).__init__(params,defaults=defaults)\n",
        "    def step(self,closure=None):\n",
        "        #Iterature through all the parameter \n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                #p.data.shape (512,784)\n",
        "                m = p.grad.data.shape[0] # 512\n",
        "                n = p.grad.data.shape[-1] # 768\n",
        "                r = self.lora_rank\n",
        "                state = self.state[p]\n",
        "                step_size = group['lr']\n",
        "                # state is a dictionary that holds all the optimizer configurations for each parameter\n",
        "                if len(state) ==0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros(r,n)\n",
        "                    state['exp_avg_sqr'] = torch.zeros(r,n)\n",
        "                    state['projection'] = torch.zeros(m,r)\n",
        "                if state['step'] % self.subspace_freq == 0:\n",
        "                    U,_,_ = torch.svd(grad)\n",
        "                    #                      m x r\n",
        "                    state['projection'] = U[:,:r] #state['projection'].shape (512,32)\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "                # Project the gradient matrix to low rank (compact space)\n",
        "                r_t = state['projection'].T @ grad # (32,512) * (512,784) = (32, 784) = r x n\n",
        "                # Exponential moving average of **low-rank projection** of gradient values\n",
        "                exp_avg = state['exp_avg'] #first moment estimate\n",
        "                # Exponential moving average of the square of the **low-rank projection** of gradient values\n",
        "                exp_avg_sqr = state['exp_avg_sqr'] # second moment estimate\n",
        "                beta1,beta2 = group['betas'] # get betas\n",
        "                exp_avg.mul_(beta1).add_((1-beta1),r_t) #update biased first moment estimate\n",
        "                exp_avg_sqr.mul(beta2).addcmul_((1-beta2),r_t,r_t) # update biased second moment estimate\n",
        "                denom = exp_avg_sqr.sqrt().add_(group['eps']) # denom.shape (32,784)\n",
        "\n",
        "                # If there is bias correction\n",
        "                if 'bias_correction' in group:\n",
        "                    bias_corrected_first_moment = 1 - beta1 ** state['step']\n",
        "                    bias_corrected_second_moment = 1 - beta2 ** state['step']\n",
        "                    step_size = step_size * math.sqrt(bias_corrected_second_moment) / bias_corrected_first_moment\n",
        "                n_t = exp_avg / denom \n",
        "\n",
        "                # Project low-rank graident matriz back t to original vectior subspace\n",
        "                #                               m x r           r x n\n",
        "                g_t = self.scaling_factor * state['projection'] @ n_t\n",
        "                state['step'] += 1\n",
        "                # Weight update\n",
        "                p.data.add_(-step_size*g_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yulmMpvMEzKM"
      },
      "source": [
        "## Weight Decomposition Low Rank Adaptation Fine Tuning (DoRA)\n",
        "\n",
        "**What is DoRA?**\n",
        "\n",
        "\n",
        "**How does it work?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q-LoRA (Quantized Fine-Tuning) \n",
        " \n",
        "## What is Q-LoRA?\n",
        "Q-LoRA is a parameter efficient fine tuning method that aims to **reduce memory footprint** of training large models (specifically LLMs)\n",
        "using some of the following innovations:\n",
        "-  4-bit NormalFloat (NF4)\n",
        "- Double quantization (quantizing the quantization constants)\n",
        "- Paged optimizers (reduce memory spikes)\n",
        "\n",
        "**NOTE**:\n",
        "- QLoRA data storage data type: nf4\n",
        "- QLoRA computation data type: bf16\n",
        "\n",
        "For 1 linear layer, Q-LoRA:\n",
        "$$\n",
        "Y^{bf16} = X^{bf16} \\text{double quantize}(c^{fp32}_1,c^{k-bit}_2,W^{NF4}) + X^{bf16} A^{bf16} B^{bf6}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## How does it work?\n",
        "\n",
        "**Block wise k-bit quantization**\n",
        "\n",
        "\n",
        "Quantization:\n",
        "$$\n",
        "x_{quantized} = X^{int8} = round(\\frac{127}{absmax(X^{fp32})}) = round(c^{fp32},X^{fp32})\n",
        "$$\n",
        "Dequantization: \n",
        "$$\n",
        "X_{dequantized} = X^{fp32} = \\frac{X^{int8}}{c^{fp32}}\n",
        "$$\n",
        "\n",
        "\n",
        "* We chunk the tensor $X \\in R^{b \\times h}$ into $N$ contigous blocks of size $B$ \n",
        "* We will get $n = (b \\times h) / B$ number of blocks\n",
        "* We quantize these blocks indepdently\n",
        "* We will get $n$ quantization constants with this quantized tensor\n",
        "\n",
        "**4-bit NormalFloat Quantization**\n",
        "- Builds on Quantile Quantization: \n",
        "    - Each quantization bin has an equal number of values assigned from input tensor\n",
        "    - It estimates the quantile of the input tensor through the empirical cummulative distribution function\n",
        "- Limitations with Quantile Quantization:\n",
        "    - Quantile Estimation algorithms have large quantization error\n",
        "    - Quantile Estimation is expensive\n",
        "- Input tesnors come from a distribution fixed up to a quantization constant -> Input tensors have the same quantiles\n",
        "\n",
        "Approach\n",
        "- 1) Estimate the $2^{k}+1$ quantiles of a theoretical N(0,I) distribution to obtain a $k$ - bit quantile quantization data type for normal distirbution\n",
        "- 2) Take this data type and normalize its values into the $[-1,1]$ range.\n",
        "- 3) Quantize an input weight tensor by normalizing it into the $[-1,1]$ range through absolute maximum rescaling\n",
        "\n",
        "How do we estimate the $2^k$ values $q_i$ of the data type as follows?\n",
        "$$\n",
        "q_i = \\frac{1}{2} (Q_X(\\frac{i}{2^k + 1}) + Q_X(\\frac{i+1}{2^k +1}))\n",
        "$$\n",
        "where\n",
        "* $i$ refers to the index into the sorted array of a tensor\n",
        "* $Q_{X}$ is the quantile function (or inverse CDF)\n",
        "\n",
        "We create asymmetric data type by estimating the quantiles $q_i$ of 2 ranges:\n",
        "- $2^{k-1}$ for neagitve part\n",
        "- $2^{k-1} + 1$ for the positive part\n",
        "\n",
        "\n",
        "**Double Quantization**\n",
        "- We firther quantize the quantization constants $c^{fp32}$ (constant of the 1st quantization) as input to second quantization\n",
        "- Memory comparison:\n",
        "    - Original quantization: 32 bit constants, block size 64 => 32/64 = 0.5 bits per parameter ($n = (b \\times h) / B$, where $B$ is 64)\n",
        "        - Intuition: \n",
        "            - For every 64 parameters you have a quantization constant added that is size 32 bit, so per parameter, you are adding 0.5 bits\n",
        "    - Double quantization: 8 bit floats, block size 256 in 2nd quantization\n",
        "        - $8/64 + 32/(64*256) = 0.127$ bits  \n",
        "            - Intuition: \n",
        "                - In original quantization, you have blocks of size 64, each block **used** to be represented by 1 quantization constant. \n",
        "                - In double quantization, you look at 256 of these blocks of 64,so you have 256 of these quantizaiton constants. You then perform quantization on the 256 constants, they are then turned to 8 bits. As a result you get 1 32bit number for every 256 blocks.\n",
        "     \n",
        "\n",
        "\n",
        "- Input: $c_2^{FP32}$\n",
        "- Output: $c_2^{FP8}$ and $c_1^{FP32}$\n",
        "where \n",
        "* $c_2^{FP8}$ is the quantized quantization constant\n",
        "* $c_1^{FP32}$ is the second level quantization constant\n",
        "\n",
        "\n",
        "**Paged Optimizers**\n",
        "- use paging feature to evict optimizer states back to CPU RAM if GPU RAM isnt enough\n",
        "- page it back into GPU when needed for gradient step\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NOTE:** stuff about quantiles and estimating quantiles\n",
        "\n",
        "* A quantile is a statistical measure that divies the distribution into equal subgroups\n",
        "* A quantile can be:\n",
        "    - Quartiles: Divide the data into 4 equal parts\n",
        "    - Deciles: Divide into 10 equal parts\n",
        "    - Percentiles: Divide into 100 equal parts\n",
        "* How to find the quantile in a distribution?\n",
        "    - 1) order the data in ascending order\n",
        "    - 2) calculate the position of the **desired quantile** : Position = number of total elements or observations $\\times$ the desired quantile (as a fraction)\n",
        "    - 3) interpolate to estimate the quantile value if the position is not an integer\n",
        "* More about CDFs and quantiles:\n",
        "    - CDF: returns the probabilities of $X$ being smaller than or equal to some value $x$, $Pr(X \\leq x) = F(x) = p$\n",
        "    - Inverse CDF (quantile function): $F^{-1}(p) = x$ \n",
        "    <center>\n",
        "    <img src=\"https://i.sstatic.net/SNViH.png\"/>\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.0000, -0.8667, -0.7333, -0.6000, -0.4667, -0.3333, -0.2000, -0.0667,\n",
            "         0.0667,  0.2000,  0.3333,  0.4667,  0.6000,  0.7333,  0.8667,  1.0000])\n",
            "tensor([1.5670, 1.4337, 1.3003, 1.1670, 1.0337, 0.9003, 0.7670, 0.6337, 0.5003,\n",
            "        0.3670, 0.2337, 0.1003, 0.0330, 0.1663, 0.2997, 0.4330])\n",
            "tensor(12)\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "import torch\n",
        "\n",
        "# We want to store the weights as 4-bit integers\n",
        "# We create 16 levels spaced btw -1 and 1\n",
        "quantiles = torch.linspace(-1,1,16)\n",
        "\n",
        "print(quantiles)\n",
        "\n",
        "# This is our data tensor\n",
        "tensor_fp32 = torch.tensor(0.567)\n",
        "\n",
        "print(torch.abs(quantiles - tensor_fp32))\n",
        "\n",
        "# We find the floating point number that is closest to 0.567 (which is 0.6), and we will\n",
        "# quantize it to that float 0.6\n",
        "index = torch.argmin(torch.abs(quantiles - tensor_fp32))\n",
        "\n",
        "# All we need to store is the index, which is just an integer (13)\n",
        "\n",
        "# Our dequantization error:\n",
        "error = 0.6 - 0.567\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYS0U7txEkuw"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opP38IOGEJMU"
      },
      "outputs": [],
      "source": [
        "# Double quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "# 4-bit Normal Float \n",
        "nf4 = torch.tensor([-1.0, -0.6961928009986877, -0.5250730514526367, -0.39491748809814453, -0.28444138169288635, -0.18477343022823334, -0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,\n",
        "0.24611230194568634, 0.33791524171829224, 0.44070982933044434, 0.5626170039176941, 0.7229568362236023, 1.0])\n",
        "print(len(nf4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3607, 0.4957, 0.1694,  ..., 0.6392, 0.8512, 0.1933],\n",
              "        [0.8317, 0.2010, 0.4518,  ..., 0.1055, 0.3967, 0.1426],\n",
              "        [0.9364, 0.7875, 0.5563,  ..., 0.3970, 0.6429, 0.7989],\n",
              "        ...,\n",
              "        [0.6362, 0.1420, 0.4050,  ..., 0.6945, 0.0891, 0.6628],\n",
              "        [0.3368, 0.7009, 0.2769,  ..., 0.5620, 0.5264, 0.5288],\n",
              "        [0.6726, 0.1954, 0.0083,  ..., 0.5836, 0.2798, 0.3326]])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Create some weight tensor\n",
        "\n",
        "x = torch.rand(100,100)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.2786, -0.0086, -0.6613,  ...,  0.2783,  0.7024, -0.6133],\n",
              "        [ 0.6634, -0.5979, -0.0963,  ..., -0.7889, -0.2066, -0.7149],\n",
              "        [ 0.8729,  0.5751,  0.1126,  ..., -0.2060,  0.2858,  0.5978],\n",
              "        ...,\n",
              "        [ 0.2724, -0.7159, -0.1900,  ...,  0.3891, -0.8218,  0.3256],\n",
              "        [-0.3265,  0.4018, -0.4461,  ...,  0.1240,  0.0527,  0.0576],\n",
              "        [ 0.3453, -0.6092, -0.9833,  ...,  0.1672, -0.4404, -0.3349]])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 2: normalize it btw -1 and 1\n",
        "x = (x * 2) -1\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-2,  0, -5,  ...,  2,  5, -4],\n",
            "        [ 5, -4, -1,  ..., -6, -1, -5],\n",
            "        [ 6,  4,  1,  ..., -1,  2,  4],\n",
            "        ...,\n",
            "        [ 2, -5, -1,  ...,  3, -6,  2],\n",
            "        [-2,  3, -3,  ...,  1,  0,  0],\n",
            "        [ 2, -4, -7,  ...,  1, -3, -2]], dtype=torch.int8)\n",
            "tensor(-7, dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Perform the quantization\n",
        "x_quantized = (((8 - 1) / x.abs().max())*x).round().to(torch.int8)\n",
        "c = ((8 - 1) / x.abs().max())\n",
        "print(x_quantized)\n",
        "print(x_quantized.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_quantized = x_quantized+8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(15, dtype=torch.int8)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_quantized.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.6250,  0.4375,  1.0000,  ..., -0.1875,  0.2500,  0.2500],\n",
              "        [-0.2500,  0.5000, -0.8750,  ...,  0.0000,  0.2500, -0.5000],\n",
              "        [-0.3750,  0.2500, -0.6250,  ..., -0.2500, -0.8750, -0.3750],\n",
              "        ...,\n",
              "        [-0.3750, -0.2500,  0.1250,  ...,  0.0000,  0.0000,  0.4375],\n",
              "        [ 0.3125,  0.3750,  0.6875,  ...,  0.3750, -0.6250,  0.6250],\n",
              "        [-0.7500, -0.8750,  0.8125,  ..., -0.4375,  0.8750,  0.8750]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_dequantized  = (x_quantized / ((16 -1)/x.abs().max())).float()\n",
        "x_dequantized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
