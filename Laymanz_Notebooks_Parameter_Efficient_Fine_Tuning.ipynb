{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMGa4otlDSEl"
      },
      "source": [
        "# Laymanz Notebooks: Parameter Efficient Fine-Tuning\n",
        "Author: Ambrose Ling\n",
        "\n",
        "**What is this notebook about?**\n",
        "\n",
        "In this notebook, we will go over some of the most fundamental ideas behind parameter efficient fine-tuning, how they work and why they have been a major advancement in the field of computer vision and generative artifical intelligence. We hope that you can walk away capable of leveraging these techniques to fine-tune your own language models or diffusion models.\n",
        "\n",
        "**What do I need to set up my environment?**\n",
        "\n",
        "All of our notebooks will only use numpy, pytorch, matplotlib for visualizations. We will not use any other third-party libraries for model development, optimization or anything like that.\n",
        "\n",
        "**How is this notebook structured?**\n",
        "1.\n",
        "2.\n",
        "3.\n",
        "\n",
        "\n",
        "**Covered papers in this notebook**\n",
        "* LoRA\n",
        "* GaLoRE\n",
        "* DoRA\n",
        "\n",
        "\n",
        "(will do after finishing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# What is Paramter Efficient Fine Tuning\n",
        "\n",
        "PEFT aims to leverage methods that reduce the cost of fine-tuning neural network models.\n",
        "Businesses, engineers, researchers may want to fine-tune state of the art language models or vision models to perform very specialized tasks for them. \n",
        "\n",
        "However the main bottleneck is that existing fine-tuning methods may involve full network training on these large models, which requires a lot of computational resources.\n",
        "\n",
        "If I want to fine-tune a model for multiple different tasks, it is very time consuming and expensive.\n",
        "\n",
        "## How to estimate the computational resources required for your model?\n",
        "- Lets assume that your model $\\theta$ has 1 billion parameters\n",
        "- The way we would calculate the memory requirement for fine-tuning such a model is as follows\n",
        "    - Parameters: 1B $\\times$ 4 bytes (32 bits)\n",
        "    - Gradients: 1B $\\times$ 4 bytes (32 bits)\n",
        "    - Optimizer States: 1B  $\\times$ 4 bytes (32 bits)$\\times$  2 (depending on the optimizer, Adam saves 2 moment statistics per parameter)\n",
        "    - Activations: can vary depending on the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear = nn.Linear(10,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.nn.modules.linear.Linear"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRUf7dezEJr2"
      },
      "source": [
        "## Low Rank Adaptation Fine Tuning (LoRA)\n",
        "\n",
        "**What is LoRA?**\n",
        "LoRA stands for Low Rank Adaptation fine-tuning. LoRA parametrizes the weight update matrix $\\Delta W$ as a low rank matrix. Authors found \n",
        "that update matrices are intrinsically low rank.\n",
        "\n",
        "**What is the goal of LoRA?**\n",
        "\n",
        "The main goal of LoRA is to enable fine-tuning of primiarly Large Language Models (also Diffusion Models) in a parameter efficient way,\n",
        "meaning without having to fine-tune or update all the weights of our model. This is desirable as this can reduce the computational cost when fine-tuning \n",
        "Large Language Models or Diffusion Models on downstream tasks\n",
        "\n",
        "**How does it work?**\n",
        "* Assume we have a pretrained model $\\theta$ where it has linear layers with weights $W_0$:\n",
        "* when we fine-tune our model, we freeze $W_0$, which prevents the pretrained weights from having gradient updates\n",
        "* LoRA decomposes the weight update matrix into 2 matrices $A \\in R^{r \\times k}$ and $B \\in R^{d \\times r}$\n",
        "* where we select $r$ , which is the rank and $r$ should be much smaller than $k$ or $d$\n",
        "* The paper showed that finetuning perforamnce using a small $r$ is on par with a large $r$ that would be used in full-finetuning \n",
        "* This shows that increasing $r$ does not help the weight update matrix cover more meaningful subspaces\n",
        "* The update formula during fine-tuning is as follows:\n",
        "    - $xW_{updated}$ = $xW_0$ + $x\\Delta W$\n",
        "    - $xW_{updated}$ = $xW_0$ + $x(A \\cdot B)\\cdot\\frac{\\alpha}{r}$\n",
        "    - where $r$ refers to the rank of low rank parametrization, $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets see analyze the dimensionality of the weight matrices\n",
        "d = 100 # rows \n",
        "k = 200 # columns\n",
        "\n",
        "r = 64 # the intrinsic low rank\n",
        "W_0 = torch.randn(d,k) \n",
        "\n",
        "A = torch.randn(r,k)\n",
        "B = torch.randn(d,r)\n",
        "\n",
        "x = torch.randn(k,k)\n",
        "\n",
        "W_0 = W_0 \n",
        "delta_W = (A @ B) @ x\n",
        "\n",
        "assert W_0.shape == delta_W.shape\n",
        "\n",
        "y = W_0 + delta_W \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why does it work?\n",
        "- It works because of this: there exists an intrinsic dimension\n",
        "    - Intrinsic dimension means the **minimum number of parameters required to achieve good performance**\n",
        "    - It also means the **lowest dimensional subspace** we can optimize our objective function in\n",
        "    - We fine-tune the model using this formula:\n",
        "    $$\n",
        "    \\theta^d = \\theta_0^D + P(\\theta^d)\n",
        "    $$\n",
        "    where:\n",
        "    * D is some higher dimension, or original dimensionality of the pretrained parameters\n",
        "    * d is some lower dimension, the dimensionality we want to perform optimization in for our \n",
        "    * P is the projection function or matrix that transforms the lower dimensional parameters to original dimensionality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Ckp6US9r8iDrEP9jW3m3VA.png\" ></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywo1YEmuEyrd"
      },
      "outputs": [],
      "source": [
        "class LoRA(nn.Module):\n",
        "    def __init__(self,rank,scale,layer):\n",
        "        self.rank = rank\n",
        "        self.scale = scale\n",
        "        self.a = nn.Parameter(torch.randn(10,self.rank))\n",
        "        self.b = nn.Parameter(torch.randn(self.rank,self.rank))\n",
        "        nn.init.normal(self.a.weight)\n",
        "        nn.init.normal(self.a.weight)\n",
        "        nn.init.zero(self.b.weight)\n",
        "        nn.init.zero(self.b.weight)\n",
        "    def forward(self,x):\n",
        "        x = x + self.a @ self.b *(self.scale/self.rank)\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVD decomposition & LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Applying LoRA to a pretrained language model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Low Rank Adaptation Fine Tuning (GaLoRE)\n",
        "\n",
        "**What is GaLoRE?**\n",
        "GaLoRE is a paper released recently aiming to tackle certain limitations of vanilla LoRA\n",
        "GaLoRE stands for gradient low-rank projection, which is a training method that allows you to still \n",
        "train with full parameters but is more **memory efficient** \n",
        "\n",
        "\n",
        "**Some of the main problems with LoRA**\n",
        "- LoRA is not able to reach good performance compared to full-parameter fine-tuning\n",
        "    - cause 1: the LoRA reparametrization changes the training dynamics\n",
        "    - cause 2: the optimal weight matrices are not low rank\n",
        "\n",
        "**How does it work?**\n",
        "- GaLoRE is used to fine-tune pretrained langauge models\n",
        "- GaLoRE approximates the gradient matrices as low rank rather than the paramter matrices (gradient matrices show to have slowly changing low-rank structure)\n",
        "- We compute 2 **projection matrices** $P \\in R^{m \\times r}$ and $Q \\in R^{n \\times r}$ to project gradient matrices to **low rank form**, $P^TGQ$\n",
        "- Only very infrequent updates applied to the projection matrices\n",
        "- GaLoRE aims to reduce the gradient statistics of both first-order and second-order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep dive into how it works\n",
        "\n",
        "In full rank training, we represent the weight update rule to be:\n",
        "$$\n",
        "W_T = W_0 + n \\Sigma_{t=0}^{T-1} \\tilde{G_t} = W_0 + n \\Sigma_{t=0}^{T-1} \\rho_t (\\tilde{G_t})\n",
        "$$\n",
        "\n",
        "* $W_T$ is weight matrix after $T$ training steps\n",
        "* $W_0$ is the inital weight matrix\n",
        "* $ \\tilde{G_t}$ is the final gradient matrix to be added to the weight matrix.\n",
        "* $\\rho_t$ is stateful gradient regularizer (optimizer)\n",
        "\n",
        "\n",
        "In low-rank training, we represent the weight update rule to be:\n",
        "$$\n",
        "W_T = W_0 + B_{T}A_{T}\n",
        "$$\n",
        "* $B \\in R^{m \\times r}$ is the low rank gradient matrix (low rank adaptors)\n",
        "* $A \\in R^{r \\times n}$ is the low rank projection matrix (low rank adaptors)\n",
        "\n",
        "In GaLore, we represent tje weight update rule to be:\n",
        "$$\n",
        "W_T = W_0 + n \\Sigma_{t=0}^{T-1} \\tilde{G_t}, \\tilde{G_t} = P_t\\rho_t(P_t^TG_tQ_t)Q_t^T\n",
        "$$\n",
        "* $P_t,Q_t \\in R^{m \\times r}, \\in R^{n \\times r}$ are projection matrices\n",
        "\n",
        "## Memory consumption comparison\n",
        "In full rank training:\n",
        "- Adam: $M,V \\in R^{m \\times n}$  \n",
        "- Gradient matrix: $G \\in R^{m \\times n}$\n",
        "- Weight matrix: $W \\in R^{m \\times n}$\n",
        "Total: $3mn$\n",
        "\n",
        "In LoRA training:\n",
        "- Adam: $M \\in R^{m \\times r},V \\in R^{n \\times r}$ for $A$,  $M \\in R^{m \\times r},V \\in R^{n \\times r}$ for $B$\n",
        "- Gradient matrix: $G \\in R^{m \\times n}$\n",
        "- Weight matrix: $W \\in R^{m \\times n}$, $A \\in R^{m \\times r}$,$B \\in R^{n \\times r}$\n",
        "Total: $$\n",
        "\n",
        "In GaLoRE training:\n",
        "- Adam: $M,V \\in R^{n \\times r}$  \n",
        "- Gradient matrix: $G \\in R^{n \\times r}$\n",
        "- Weight matrix: $W \\in R^{m \\times n}$\n",
        "- Projection matrices: $P \\in R^{m \\times r}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Original Adam Optimizer Algorithm**\n",
        "<center><a href=\"https://ibb.co/JK5nkmd\"><img src=\"https://i.ibb.co/xDJh5Xs/Screenshot-2024-06-05-at-1-32-18-PM.png\" alt=\"Screenshot-2024-06-05-at-1-32-18-PM\" border=\"0\"></a></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainng code for the Adam Optimizer\n",
        "\n",
        "from torch.optim import Optimizer\n",
        "import math\n",
        "\n",
        "class Adam(Optimizer):\n",
        "    def  __init__(self,params,lr = 1e-6,betas = (0.99,0.9),eps=1e-6,weight_decay=0.0):\n",
        "        defaults = dict(lr=lr,betas=betas,weight_decay=weight_decay,eps=eps)\n",
        "        super().__init__(params,defaults=defaults)\n",
        "    def step(self,closure=None):\n",
        "        #Iterature through all the parameter \n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "                step_size = group['lr']\n",
        "                # state is a dictionary that holds all the optimizer configurations for each parameter\n",
        "                if len(state) ==0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    state['exp_avg_sqr'] = torch.zeros_like(p.data)\n",
        "                exp_avg = state['exp_avg'] #first moment estimate\n",
        "                exp_avg_sqr = state['exp_avg_sqr'] # second moment estimate\n",
        "                beta1,beta2 = group['betas'] # get betas\n",
        "                exp_avg.mul_(beta1).add_((1-beta1),grad) #update biased first moment estimate\n",
        "                exp_avg_sqr.mul(beta2.addcmul_((1-beta2)),grad,grad) # update biased second moment estimate\n",
        "                denom = exp_avg_sqr.sqrt().add_(group['eps'])\n",
        "\n",
        "                # If there is bias correction\n",
        "                if group['bias_correction'] == True:\n",
        "                    bias_corrected_first_moment = 1 - beta1 ** state['step']\n",
        "                    bias_corrected_second_moment = 1 - beta2 ** state['step']\n",
        "                    step_size = step_size * math.sqrt(bias_corrected_second_moment) / bias_corrected_first_moment\n",
        "\n",
        "                # Weight update\n",
        "                p.data.addcdiv_(-step_size,exp_avg,denom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**GaLoRE+Adam Optimizer Algorithm**\n",
        "<center><a href=\"https://ibb.co/nDD9Sj7\"><img src=\"https://i.ibb.co/gDDNCJS/Screenshot-2024-06-05-at-4-02-38-PM.png\" alt=\"Screenshot-2024-06-05-at-4-02-38-PM\" border=\"0\"></a></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainng code for the GaLoRE Optimizer (Ambrose's implementation)\n",
        "\n",
        "from torch.optim import Optimizer\n",
        "import torch\n",
        "import math\n",
        "\n",
        "class GaLoREOptimizer(Optimizer):\n",
        "    def  __init__(self,params,lr = 1e-6,betas = (0.99,0.9),eps=1e-6,weight_decay=0.0,rank=32,subspace_freq=10,lora_scale=1.0):\n",
        "        defaults = dict(lr=lr,betas=betas,weight_decay=weight_decay,eps=eps, )\n",
        "        self.subspace_freq = subspace_freq # corresponds to T, subspace change frequency\n",
        "        self.lora_rank = rank # corresponds to LoRA rank\n",
        "        self.scaling_factor = lora_scale\n",
        "        super(GaLoREOptimizer,self).__init__(params,defaults=defaults)\n",
        "    def step(self,closure=None):\n",
        "        #Iterature through all the parameter \n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                #p.data.shape (512,784)\n",
        "                m = p.grad.data.shape[0] # 512\n",
        "                n = p.grad.data.shape[-1] # 768\n",
        "                r = self.lora_rank\n",
        "                state = self.state[p]\n",
        "                step_size = group['lr']\n",
        "                # state is a dictionary that holds all the optimizer configurations for each parameter\n",
        "                if len(state) ==0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros(r,n)\n",
        "                    state['exp_avg_sqr'] = torch.zeros(r,n)\n",
        "                    state['projection'] = torch.zeros(m,r)\n",
        "                if state['step'] % self.subspace_freq == 0:\n",
        "                    U,_,_ = torch.svd(grad)\n",
        "                    #                      m x r\n",
        "                    state['projection'] = U[:,:r] #state['projection'].shape (512,32)\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "                # Project the gradient matrix to low rank (compact space)\n",
        "                r_t = state['projection'].T @ grad # (32,512) * (512,784) = (32, 784) = r x n\n",
        "                # Exponential moving average of **low-rank projection** of gradient values\n",
        "                exp_avg = state['exp_avg'] #first moment estimate\n",
        "                # Exponential moving average of the square of the **low-rank projection** of gradient values\n",
        "                exp_avg_sqr = state['exp_avg_sqr'] # second moment estimate\n",
        "                beta1,beta2 = group['betas'] # get betas\n",
        "                exp_avg.mul_(beta1).add_((1-beta1),r_t) #update biased first moment estimate\n",
        "                exp_avg_sqr.mul(beta2).addcmul_((1-beta2),r_t,r_t) # update biased second moment estimate\n",
        "                denom = exp_avg_sqr.sqrt().add_(group['eps']) # denom.shape (32,784)\n",
        "\n",
        "                # If there is bias correction\n",
        "                if 'bias_correction' in group:\n",
        "                    bias_corrected_first_moment = 1 - beta1 ** state['step']\n",
        "                    bias_corrected_second_moment = 1 - beta2 ** state['step']\n",
        "                    step_size = step_size * math.sqrt(bias_corrected_second_moment) / bias_corrected_first_moment\n",
        "                n_t = exp_avg / denom \n",
        "\n",
        "                # Project low-rank graident matriz back t to original vectior subspace\n",
        "                #                               m x r           r x n\n",
        "                g_t = self.scaling_factor * state['projection'] @ n_t\n",
        "                state['step'] += 1\n",
        "                # Weight update\n",
        "                p.data.add_(-step_size*g_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yulmMpvMEzKM"
      },
      "source": [
        "## Weight Decomposition Low Rank Adaptation Fine Tuning (DoRA)\n",
        "\n",
        "**What is DoRA?**\n",
        "\n",
        "\n",
        "**How does it work?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q-LoRA (Quantized Fine-Tuning) \n",
        " \n",
        "**What is Q-LoRA?**\n",
        "\n",
        "**How does it work?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYS0U7txEkuw"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opP38IOGEJMU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
