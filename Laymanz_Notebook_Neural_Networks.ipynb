{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":12722,"status":"ok","timestamp":1714698084624,"user":{"displayName":"Ambrose Ling","userId":"02772582281435222926"},"user_tz":240},"id":"ZX1CyCYO4A7p"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Laymanz Notebooks: Training your first deep learning model\n","Author: Ali Ahmad & Amrbose Ling\n","\n","**Our goal is to get rid of abstractions and black boxes when learning about ML**\n","\n","**What is this notebook about?**\n","\n","In this notebook, we will go over some of the fundamental ideas behind deep learning, neural networks, model training, inference, backpropagation, loss functions, optimizers.\n","\n","**What do I need to set up my environment?**\n","\n","All of our notebooks will only use numpy, pytorch, matplotlib for visualizations. If you are very eager to learn about what PyTorch is and how it works, check out this super detailed notebook on PyTorch! If you are running this on colab you can just import the packages, if you are running this notebook locally , just remember to `pip install numpy torch matplotlib`. Check [here](https://pytorch.org/get-started/locally/) to see which torch version depending on the hardware you have.\n","\n","**How is this notebook structured?**\n","\n","Each notebook will have\n","\n","[**How to use matplotlib for plotting**](https://colab.research.google.com/github/amanchadha/aman-ai/blob/master/matplotlib.ipynb#scrollTo=1-AcMM6NSmP-)\n","\n","\n","## Breakdown\n","*   What is deep learning?\n","*   What is a neuron? What is an activation?\n","*   What is a neural network?\n","*   What is a multi-layer perceptron?\n","*   What is a computation graph?\n","*   What is autograd?\n","*   What is a forward pass?\n","*   What is a loss function?\n","*   What is an optimizer?\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision.datasets import MNIST\n","from torch.utils.data import DataLoader,Dataset"]},{"cell_type":"markdown","metadata":{},"source":["# What is deep learning?\n","\n","You can find many definitions online, but here is my definition:\n","Deep learning involves extracting meaningful insights from data using deep neural networks.\n","Deep learning is a branch of Machine Learning that specializes in the use of neural networks to make predictions.\n","\n","\n","# What can deep learning be used for?\n","* Classification\n","    - Binary classification\n","    - Multiclass classification\n","    - Multilabel classficiation\n","* Regression\n","    - Linear Regression\n","    - Logistic Regression\n","    - Polynomial Regression\n","\n","Ambrose's interpretation:\n","Deep learning is about feeding a neural network a bunch of data, the neural network produces some \n","output, we see how wrong they were compared to what we want, we tell it \"hey you were wrong you gotta change how you think so you get it right next time!\" then we change it, we repeat this until we iterate through all of our data.\n","\n","The usual receipe for a deep learning task:\n","Step 1: Find a bunch of data for the thing you want to train your model on\n","Step 2: Preprocess the data to turn it into the right form\n","Step 3: Train the model by feeding it the data\n","Step 4: Evaluate it, find ways to make it better or train it again "]},{"cell_type":"markdown","metadata":{},"source":["# What is a neuron?\n","A neuron are nerve cells in our brains, responsible for transmitting electrical signals from one part of the brain to another. \n","\n","## Properties of neurons:\n","- They receive their signals via their dendrites\n","- They have snynapses that module the electrical signals it receives (between dendrites and axons)\n","- They fire an output signal only when the total strength of the input signal exceed a certain threshold"]},{"cell_type":"markdown","metadata":{},"source":["# What is a perceptron?\n","\n","A perceptron is a mathematical model of a biological neuron. Hence we use mathematical operations to model the properties of a neuron.\n","\n","## Properties of a perecptron?\n","- electrical signals are represented by numerical values (some vector)\n","- modulation is modelled by multiplying some weight value to the input signal / values\n","- we model the total strength of a signal by performing a weighted sum of the inputs \n","- we apply an activation function or a step function to model the firing of the signal upon some threshold\n","- it is believed that neurons remain inactive until the net input to the cell body reaches a certain threshold"]},{"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://miro.medium.com/v2/resize:fit:2902/format:webp/1*hkYlTODpjJgo32DoCOWN5w.png\" height=230 width=500/></center>\n","<center> On the left you have the biological neuron, on the right you have the artificial neuron </center>"]},{"cell_type":"markdown","metadata":{},"source":["### How do we represent a perceptron mathematically?\n","\n","$$\n","y = \\sigma ( \\Sigma w_i x_i + b )\n","$$\n","\n","where : \n","* y: represents the output from the neuron\n","* w represents the weight associated with this neuron\n","* x: represents the input to the neuron\n","* b: represets the bias added to each \n","\n","Ambrose's intuition:\n","Think of each neuron having its own behaviour or its own state, it behaves differently from other neurosn which is why each\n","has a different weight and bias associated with it.\n"]},{"cell_type":"markdown","metadata":{},"source":["### How do we represent all these quantities mathematically?\n","Think of different ways you may want to represent inputs, and I can list some examples for some of the most common machine learning applications, all these are different modalities. Since we mentioned that the key to \n","  \n","\n","Lets try to develop an intuition for how you would quantitatively represent data?\n","\n","1. Usecase: Predicting house prices \n","Scenario: Lets say i want to predict the price of houses in Toronto given some information of a house(expensive af)\n","What does data look like:  For this scenario, I want to probably find some way to represent that information of a house **quantitatively**\n","What does input look like: Some collection of numbers that represent some characteristics of the home\n","What does output look like: A number (float/double) representating the price of the home\n","A house can be represented by:\n","    - int: how many bedrooms are in this house\n","    - int: how many square feet is this house\n","    - int: how many bathrooms it has\n","    - String: where is this house (the location)\n","    - String: the population of the city it is in\n","\n","2.  Usecase: Predicting postiive and negative sentiment from text\n","Scenario: Lets say i want to predict if a tweet contains harmful or positive intent right, you know those goddamn politicans\n","What does data look like? In this scenario, the data would probably be the tweets themselves, which is a series of strings.\n","\n","\n","3. Usecase: Predicting the price of Bitcoin \n","Scenario: Lets say i want to predict if the price of bitcoin. \n","What does input look like: A collection of numbers representing past bitcon pries\n","The price of bitcoin can be represented by:\n","    - list of ints: \n","\n","\n","4. Usecase: "]},{"cell_type":"markdown","metadata":{},"source":["### Model Width VS Model Depth\n","\n","**Larger width** (vertically, more neurons): usually means that the neural network has the capacity to remember more feature or encode more features in the weight connecitons or weight matrix. \n","* With more neurons in each layer, you can capture more delicate details with more neurons. \n","* Think of the more neurons you have in each layer, you have more processing units and internal states corresponding to each input unit. \n","* Think of if you have 1 x 10 input, 15 neurons VS 1 x 10 input, 100 neurons, you have much more overall weight connections to the input, so you can capture each intricate value in the input more precisely with more weights.\n","* Think of F1 cars right when they get to the pit stop, if you have only 5 people changing the tires, wiping the windows, pumping gas VS when you have 20 people , you would be be able to be more precise about what you do to the car, 5 people would probably capture less of the tasks they need to do on the car. People (neurons), the car (input).\n","\n","**Larger depth** (more layers), usually means that the neural network can remember or encode more complex,high dimensional features from the training data.\n","\n","* The way i think could help also understand is that think of width as having more functions to model your data, but more functions do not necessarily mean that the functions are more complex. \n","* Increasing the width is similar to going from 1 function: y = mx+b to 20  functions, 20 y = wx+b's. You may be able to capture specific changes in the input data better with more lines. But they are still linear functions and it would always be linear\n","* But with greater depth, you can chain non-linearities together as you apply activation functions and additional weights. So now think of 20 y = (wa(wa(wx+b)+b)+b), this entire function gets more and more complex and you introduce more non-linearity at each layer.\n","* So going from 20 y=wx+b's to 20 y = (wa(wa(wx+b)+b)+b) is what enables you to capture a much more complicated function that fits your training data."]},{"cell_type":"markdown","metadata":{},"source":["### Rank\n","Rank refers to the number of dimensions a tensor has\n","\n","- Rank 0:  referred as a **scalar**, 1 single value\n","- Rank 1:  referred as a **vector**, 1 list of values\n","- Rank 2:  referred as a **matrix**, 1 2d array of values\n","- Rank 3:  referred as a **3D tensor**, you can think of as a cube of numbers or a stack of a number of 2D matrices\n","\n","\n","### Shape \n","Shape is an array of numbers representing the length of each dimension. \n","You can understand this as the number of elements along each dimension\n","\n","```python\n","x = np.array([[[1],[2]],[[3],[4]]])\n","```\n","\n","Ambrose's intuition:\n","The way I like thinking about shapes is in terms of boxes.\n","Lets say the shape of tensor `x` is `(2,4,5)`. This means that there are 2 big boxes. Within those 2 big boxes, each of the 2 big boxes has 4 boxes in it\n","Then for each of the 4 boxes you then have 5 boxes in each one.\n","\n","One very typical example tensor is with shape `(B,C,H,W)`, for instance `(8,3,100,100)`\n","You have 8 boxes, or that means 8 samples\n","Within each box or sample, you have 3 boxes: 1 box for each channel\n","\n","\n","**NOTE:**\n","When building your neural network in PyTorch (or any deep learning framework), it is very very useful to check the shapes of your tensors at different operations you execute. One of the most common errors is `Shape Mismatch Error` where you are trying to applying illegal operations on tensors because their shapes don't \n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Hn3xTzct-b84"},"outputs":[],"source":["\n","# 1D: Array\n","x = np.array([0.12,0.23,2.34])\n","\n","# 2D: Matrix\n","x = np.array([[0.1232,0.3445,0.345532],[0.1232,0.3445,0.345532]])\n","\n","# Why do we use matrices?\n","# There are many highly efficient linear algebra libraries (NumPY, PyTorch) that are optimized to perfrom matrix multiplications extremely fast\n","# Using matrices allows us to perform operations in PARALLEL much faster to doing sequential operations\n","\n","\n","# Matrix\n","x = np.array([[0,1,2,3,4],[2,3,5,67,5]])\n","\n","# Tensor\n","x = np.array([[0,1,2,3,4],[2,3,5,67,5],[10,20,40,20,2]])\n","\n","# A tensor is nothing but a bigger matrix, it is an array that carries numerical data or think of a tensor as a multi-dimensional array. \n","# Usually matrices are  m x n, tensors can be m x n x c x p ...\n"]},{"cell_type":"markdown","metadata":{},"source":["### Why does neural network architecture matter?\n","When we talk about the neural network architecture, we are referring to the specific arrangement of neurons, the connections of neurons,layers. The specific architecture dictates the capabilities of the model, the specific data it is best suited for, the features it would excel at capturing, the specific tasks it is suited for."]},{"cell_type":"markdown","metadata":{},"source":["**Ambrose Yapping**\n","\n","\n","So how do you choose the right neural network architecture?\n","From what I know, it is almost the best to follow what somebody has done before. Reinventing the wheel is almost never a good idea unless your approach is to purely experiment with the architecture. If you are looking to accomplishing a task in ML, ask yourself if you even really need ML to do it. And \n","\n","From my experience, a lot of things seem to work theoretically, but almost never practically. So choose your experiments wisely.\n","\n","For example, `YoLo` architecutre has been experimentally shown to perform well in object detection. So if you want to train a ML model to detect pedestrains or cars, chances are using that architecture is a good idea VS putting together your own.\n"]},{"cell_type":"markdown","metadata":{},"source":["### What is PyTorch?\n","\n","PyTorch is a neural network library that lets you build and trian neural networks with their very comprehensive collection of APIs.\n","\n","1. **Tensor Operations**: Basic operations for creating, manipulating, and transforming tensors.\n","2. **Mathematical Operations**: Functions for performing arithmetic, linear algebra, and complex mathematical computations.\n","3. **Neural Network Operations**: Layers, activation functions, loss functions, and other building blocks for constructing neural networks.\n","4. **Data Manipulation**: Functions for data loading, preprocessing, and augmentation.\n","5. **Optimization**: Algorithms for updating model parameters, such as SGD, Adam, etc.\n","6. **Autograd**: Operators supporting automatic differentiation.\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tensor Operations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## -- Tensor Creation --\n","import torch\n","\n","# Create a tensor from a list\n","a = torch.tensor([1, 2, 3, 4])\n","print(a)\n","\n","# Create a tensor with random values\n","b = torch.rand(3, 3)\n","print(b)\n","\n","# Create a tensor of zeros\n","c = torch.zeros(2, 2)\n","print(c)\n","\n","# Create a tensor of ones\n","d = torch.ones(2, 3)\n","print(d)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## -- Arithmetic Operations --\n","\n","x = torch.tensor([1, 2, 3])\n","y = torch.tensor([4, 5, 6])\n","\n","# Addition\n","z = x + y\n","print(z)  # tensor([5, 7, 9])\n","\n","# Subtraction\n","z = x - y\n","print(z)  # tensor([-3, -3, -3])\n","\n","# Multiplication\n","z = x * y\n","print(z)  # tensor([4, 10, 18])\n","\n","# Division\n","z = x / y\n","print(z)  # tensor([0.2500, 0.4000, 0.5000])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## -- Matrix Multiplication Operations --\n","\n","a = torch.tensor([[1, 2], [3, 4]])\n","b = torch.tensor([[5, 6], [7, 8]])\n","\n","# Matrix multiplication\n","c = torch.mm(a, b)\n","print(c)  # tensor([[19, 22], [43, 50]])\n","#NOTE: the shape of the resulting tensor is m x n if a is of shape ( m x a ), b is of shape ( a x n) \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## -- Element-wise operations --\n","\n","a = torch.tensor([[1, 2], [3, 4]])\n","b = torch.tensor([[5, 6], [7, 8]])\n","\n","# Element-wise multiplication\n","c = a * b\n","print(c)  # tensor([[ 5, 12], [21, 32]])\n","\n","# Element-wise exponentiation\n","d = a ** 2\n","print(d)  # tensor([[ 1,  4], [ 9, 16]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## -- Reduce Operations -- \n","a = torch.tensor([1, 2, 3, 4])\n","\n","# Sum\n","sum_a = torch.sum(a)\n","print(sum_a)  # tensor(10)\n","\n","# Mean\n","mean_a = torch.mean(a.float())\n","print(mean_a)  # tensor(2.5)\n","\n","# Max\n","max_a = torch.max(a)\n","print(max_a)  # tensor(4)\n","\n","# Min\n","min_a = torch.min(a)\n","print(min_a)  # tensor(1)\n","\n","#NOTE: these operations also change the dimension of the tensor, notice we go from [N] to [1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## -- Indexing and Slicing -- \n","\n","a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","\n","# Select the first row\n","row = a[0, :]\n","print(row)  # tensor([1, 2, 3])\n","\n","# Select the first column\n","col = a[:, 0]\n","print(col)  # tensor([1, 4, 7])\n","\n","# Select a submatrix\n","submatrix = a[0:2, 1:3]\n","print(submatrix)\n","# tensor([[2, 3],\n","#         [5, 6]])\n"]},{"cell_type":"markdown","metadata":{},"source":["### Neural Network operations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Layer operations\n","in_features = 10\n","out_features = 5\n","\n","# Linear layers(Fully connected layers)\n","x = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n","layer = nn.Linear(in_features,out_features)\n","output_tensor = layer(x)\n","print(output_tensor)\n","print(layer.weight.data)\n","print(layer.bias.data)\n","#NOTE: usually the last dimension is the feature dimension\n","\n","\n","# Convolutional layers (Conv1d, Conv2d, Conv3d)\n","# Conv 1d\n","# shape: (batch size, number of channels, sequence length of the input sequence)\n","x = torch.randn(1,3,10) # Create a input signal with sequence length 10 and a channel depth of 3 \n","in_channels = 10\n","out_channels = 20\n","kernel_size = 3\n","stride = 1\n","padding = 0\n","layer = nn.Conv1d(in_channels,out_channels,kernel_size,stride,padding)\n","#See the output tensor and its shape\n","output_tensor = layer(x)\n","print(output_tensor)\n","print(output_tensor.shape)\n","print(layer.weight.data)\n","print(layer.weight.data.shape)\n","print(layer.bias.data.shape)\n","#NOTE: PyTorch convolutions take in input where the channel dimension is in the middle\n","#Check out this notebook for more info on convolutions and how they work\n","\n","#Conv 2d\n","# shape: (batch size, number of channels, height of input signal, width of input signal)\n","x = torch.randn(1,3,32,32) # Create a input signal with sequence length 10 and a channel depth of 3 \n","in_channels = 3\n","out_channels = 12\n","kernel_size = (3,3)\n","stride = 1\n","padding = 0\n","layer = nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding)\n","output_tensor = layer(x)\n","print(output_tensor)\n","print(output_tensor.shape)\n","print(layer.weight.data)\n","print(layer.weight.data.shape)\n","print(layer.bias.data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalization operations\n","\n","# NLP example\n","x = torch.randn(1,16,32,32)  #(batch size = 1, num of channels = 16, height = 32, width = 32)\n","\n","# Batch Normalization:  computes a mean and variance FOR EACH FEATURE (each channel)\n","num_features = 16\n","normalization = nn.BatchNorm2d(num_features)\n","output_tensor = normalization(x)\n","\n","# Layer Normalization: compute a mean and variance FOR EACH SAMPLE ()\n","num_features = 16\n","normalization = nn.LayerNorm(num_features)\n","output_tensor = normalization(x)\n","\n","\n","# NLP example\n","x = torch.randn(1,16,100) #(batch size = 1, num of channels = 16, sequence length = 100)\n","\n","# Batch Normalization:  computes a mean and variance FOR EACH FEATURE (each channel)\n","num_features = 16\n","normalization = nn.BatchNorm1d(num_features)\n","output_tensor = normalization(x)\n","\n","\n","# Layer Normalization: compute a mean and variance FOR EACH SAMPLE ()\n","num_features = 16\n","normalization = nn.LayerNorm(num_features)\n","output_tensor = normalization(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Activation Functions\n","\n","x = torch.randn(1,10)\n","\n","# ReLU: f(x)  = x if x >0 else 0 \n","activation_function = nn.ReLU()\n","output_tensor = activation_function(x)\n","\n","# Sigmoid: f(x) = 1 / (1 + e^-x)\n","activation_function = nn.Sigmoid()\n","output_tensor = activation_function(x)\n","\n","# Tanh: f(x)  = tanh(x)\n","activation_function = nn.Sigmoid()\n","output_tensor = activation_function(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss functions\n","# these functions measure how well the output values match the ground truth values\n","\n","y = torch.randn(1,3,10)\n","y_pred = torch.randn(1,3,10)\n","\n","# MSE (Mean Squared Error) Loss: loss = (y - y_pred)^2\n","loss_function = nn.MSELoss()\n","loss = loss_function(y_pred,y)\n","\n","# Cross Entropy Loss\n","loss_function = nn.CrossEntropyLoss()\n","loss = loss_function(y_pred,y)\n","\n","# Binary Cross Entropy Loss\n","loss_function = nn.BCELoss()\n","loss = loss_function(y_pred,y)\n","\n","\n","# KL Divergence Loss\n","loss_function = nn.KLDivLoss()\n","# if not log_target: # default\n","#     loss_pointwise = target * (target.log() - input)\n","# else:\n","#     loss_pointwise = target.exp() * (target - input)\n","\n","loss = loss_function(y_pred,y)\n"]},{"cell_type":"markdown","metadata":{},"source":["##  How do you train a neural network to do something you want?\n","\n","* Data Preparation & Preprocessing\n","    * Step 1: Find a bunch of data for the thing you want to train your model on\n","    * Step 2: Preprocess the data to turn it into the right form\n","\n","* Model training\n","    * Step 1: Pass data to the model (forward pass) to get model output\n","    * Step 2: Compute the loss between data and model output\n","    * Step 3: Perform backpropagation (backward pass)\n","    * Step 4: Perform gradient descent and weight updates\n","\n","* Model Evaluation\n","    * Step 1: Evaluate it to assess its performance\n","    * Step 2: Assess its performance on test data\n","\n","\n","\n","In this notebook we will put more emphasis on model training, \n","The most common training loop you will ever see:\n","```python \n","for epoch in range(num_epochs):\n","    for batch in training_data:\n","        output = model(batch.x) \n","        loss = loss_fn(batch.y,output)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","```"]},{"cell_type":"markdown","metadata":{},"source":["**Ambrose Yapping**\n","`Epoch` refers to how many times you go through your entire training data. Sometimes people use `training_steps` in different settings and depneding on the training task. For example, "]},{"cell_type":"markdown","metadata":{},"source":["# Preparing your data (Data perspective)\n","* Depending on the data you have, you have different ways to **preprocess** your data\n","* Some of the most common modalities out there are text, images, audio."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Preparing your data (PyTorch perspective)\n","* In PyTorch, a `Dataset` object is a class that allows you to access samples of your data. This class also allows you to perform certain data transformations to process the raw samples you grab from your dataset\n","* In case you dont know, a **sample** just means 1 pair of input and output. So for a image classification task, a sample may be (x: image,y: label), in text sentiment analysis, sample may be (x: string of text,y: float probability).\n","\n","* Lets say you have a dataset called `MyDataset`,it inherits the `Dataset` class. It represents a collection of data samples. \n","    ```python\n","    # \n","    class MyDataset(Dataset):\n","        ...\n","        def __getitem__(self,index):\n","            return\n","\n","    ```\n","    - What this class lets you do is that you can specify the logic for accessing 1 sample\n","    - So when you do `dataset[0]` calls `__getitem__()` and a sample of data will be returned\n","    - you can also apply transformations that would be applied to all the samples in your dataset when you fetch them\n","        - inside `__getitem__()`, you can apply transformations to the input and output by doing `x = self.transform(x)` and `y = self.target_transform(y)`.\n","        - **When will I do this?**, some common usecases\n","            - Transforms:\n","                - Images: cropping, resizing, normalization\n","                - Text: tokenization (turning words into numbers), padding and truncation\n","                - Audio: resampling, normalization, augmentation\n","            - Target Transform:\n","                - one hot encoding\n","                - encoding labels\n","                - normalization (coordinates)\n","                - format conversions\n","        - NOTE: the most common application of transformations is on image modalities, for text we have designated components that specifically do preprocessing (tokenizer) \n","* You can also define specific ways you want to grab samples from the dataset through the use of a sampler or `Sampler` class, which intuitively dictates how you sample data from your dataset.\n","    ```python\n","    class MySampler(Sampler):\n","        ...\n","        def __iter__(self):\n","            for i in range(self.N):\n","                yield i \n","    ```\n","    - it is used to specify the dataloading order, and specifies the indexes\n","    - more specifically it is an iterable dataset\n","* As for a `DataLoader`, this object is the intermediate process that prepares the data we take from the data into batches.\n","    ```python\n","    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n","    ```\n","    - the DataLoader receives the `dataset` object as input and returns the dataloader \n","### How they all work together:\n","<center>\n","<a href=\"https://ibb.co/ZMgcwc4\"><img src=\"https://i.ibb.co/W2zBdB8/Screenshot-2024-05-30-023025.png\" alt=\"Screenshot-2024-05-30-023025\" border=\"0\"></a></center>\n","\n","* 1. the dataset class allows you to index into different samples in your dataset\n","* 2. your CPU has different workers that grab the samples responsible for constructing a batch\n","* 3. the CPU workers load the queried samples into a queue. \n","* 4. the sampler class also provides which indices do we need for \n","* 4. the dataloader performs the collating procedure, which draws samples in the queue and puts them into a batch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Here is an example of a collating function\n","\n","def collate_fn(samples):\n","    return batch\n","\n","# As input, the collate function takes the raw batch_size number of samples\n","# It then performs some processing or you can define some custom logic\n","# to turn these samples into tensors"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n","\n","        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n","\n","        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n","\n","        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])]\n","torch.Size([64, 1, 28, 28])\n","torch.Size([64, 1, 10])\n","<class 'list'>\n"]},{"name":"stderr","output_type":"stream","text":["/Users/ambroseling/miniforge3/envs/nucleaise/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n","  warnings.warn(\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torchvision.datasets import MNIST\n","from torch.utils.data import DataLoader,Dataset\n","import torch.nn.functional as F\n","from torchvision.transforms import v2\n","from torchvision.transforms import functional as TF \n","\n","# Load the MNIST dataset\n","dataset = MNIST('',train=True,download=True,transform=v2.Compose([v2.ToTensor()]),target_transform=v2.Compose([\n","                                lambda x:torch.LongTensor([x]), # or just torch.tensor\n","                                lambda x:F.one_hot(x,10)]))\n","\n","\n","# Create a dataloader for the dataset\n","dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n","\n","# What is happening here?\n","# Just like what we described before, the dataloader helps us fetch batches of data to be fed to our model\n","# We create an iterator with the iter() method, that allows us to iterate through the elements of the dataloader\n","# When we do :\n","# for batch in dataloader:\n","#   ...\n","# We create an iterator and executes the next() method to move onto the next batch after each iteration of the loop\n","print(next(iter(dataloader))) #each batch is a list\n","print(next(iter(dataloader))[0]) # at position 0, we have the x (or images)\n","print(next(iter(dataloader))[0].shape) # When you look at the shape, \n","\n","print(next(iter(dataloader))[1].shape) # at position 1, we have the y (or labels)\n","\n","print(type(next(iter(dataloader))))\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.1647, 0.4627, 0.8588, 0.6510, 0.4627,\n","          0.4627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.4039, 0.9490, 0.9961, 0.9961, 0.9961, 0.9961,\n","          0.9961, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0706, 0.9098, 0.9961, 0.9961, 0.9961, 0.9961,\n","          0.9961, 0.9333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.4078, 0.9569, 0.9961, 0.8784, 0.9961,\n","          0.9961, 0.9961, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9961, 0.8235, 0.9961,\n","          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.8078, 0.9961, 0.9961,\n","          0.9961, 0.9961, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961,\n","          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.5373, 0.9922, 0.9961,\n","          0.9961, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.1569, 0.8392, 0.9804, 0.9961, 0.9961, 0.9961,\n","          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.3176, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961,\n","          0.9961, 0.9961, 0.5725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.4314, 0.9647, 0.9961, 0.9961, 0.9961,\n","          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.3490, 0.3490, 0.3647,\n","          0.9412, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n","          0.5020, 0.9961, 0.8588, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n","          0.9961, 0.9961, 0.8392, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412,\n","          0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6941,\n","          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9412,\n","          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n","          0.8431, 0.2471, 0.1412, 0.0000, 0.2000, 0.3490, 0.8078, 0.9961,\n","          0.9961, 0.5451, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.7725,\n","          0.9961, 0.9961, 0.8706, 0.7059, 0.9451, 0.9961, 0.9961, 0.9922,\n","          0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n","          0.4118, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9255,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0275, 0.4588, 0.4588, 0.6471, 0.9961, 0.9961, 0.9373, 0.1961,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","          0.0000, 0.0000, 0.0000, 0.0000]]])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Lets see the dataset sample\n","# Each sample is a tuple (remeber it is a pair of x and y)\n","# THis is the x (image x)\n","print(dataset[10][0])\n","\n","# This is the label for the corresponding \n","print(dataset[10][1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lets see what is the shape of the sample\n","print(dataset[10][0].shape)\n","# This is the shape of the image\n","\n","print(dataset[10][1].shape)\n","# This is the shape of the "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(dataloader,model,optimizer,profile_memory):\n","    global_step = 0\n","    progress_bar = tqdm(range(0,10*len(dataloader)),initial = global_step,desc=\"Steps: \")\n","    for epoch in range(10):\n","        for batch in dataloader:\n","            x = batch[0]\n","            y = batch[1].float().squeeze()\n","            y_pred = model(x).float()\n","            loss = F.mse_loss(y_pred.cpu(),y)\n","            y_pred = torch.argmax(y_pred.cpu(),dim=1)\n","            y = torch.argmax(y,dim=1)\n","            acc = sum(y_pred == y)\n","            logs = {\"loss \":loss.detach().item(),\"accuracy \":acc}\n","            progress_bar.set_postfix(**logs)\n","            global_step +=1\n","            progress_bar.update(1)\n","            loss.backward()\n","            import ipdb; ipdb.set_trace()\n","            optimizer.step()\n","            optimizer.zero_grad()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Creating our very own neural network engine\n","\n","Somtimes it may be confusing to understand what happens under the hood when you train a neural network in PyTorch. Just like Andrej Karpathy's video on backpropagation, I would like to extend it and give more intuition as to what happens when you train a neural network. \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyPy/ZaTDRYGonjxONkNzLGo","gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
